{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b2c861",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4986542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a13440",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa9af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/Feras/Downloads/breast-cancer.csv\")\n",
    "\n",
    "# We divide features and target variables to implement Feature Selection\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a9d08",
   "metadata": {},
   "source": [
    "## Data Preprocessing / Normalizing data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6d6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features to the range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Scale X_test using the same scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e642e4",
   "metadata": {},
   "source": [
    "Min-Max scaling rescales the features to a defined range (often [0, 1]), while maintaining the relationships between the original data points. This is especially crucial when dealing with features of varied scales, as no feature should dominate others in terms of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c40ca9",
   "metadata": {},
   "source": [
    "## Perform Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c545ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SelectKBest with chi-squared test\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=6)\n",
    "\n",
    "# Fitting selector to training data\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get selected features for better interpretability\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "\n",
    "# Selecting features\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c237be",
   "metadata": {},
   "source": [
    "For feature selection, the chi-squared test works best when working with categorical target variables and either numerical or categorical input characteristics. In this instance, the input features comprise both categorical and numerical characteristics linked to the diagnosis of breast cancer, while the target variable (diagnostic) is categorical, indicating whether a tumor is malignant or benign.\n",
    "SelectKBest with chi-squared test is computationally efficient compared to other approaches like recurrent feature elimination (RFE), which require training the model many times. Because it assesses every feature separately, it can be used with big datasets that contain a lot of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7392cf",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c2c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # For this task we will use Single hidden layer with 100 neurons\n",
    "    activation='relu',  # we implement ReLU activation function\n",
    "    solver='adam',  # We utilize Adam optimizer\n",
    "    alpha=0.0001,  # refers to L2 regularization strength\n",
    "    batch_size=32,  # Batch size of 32\n",
    "    learning_rate_init=0.001,  \n",
    "    max_iter=200,  \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035ce37",
   "metadata": {},
   "source": [
    "A single hidden layer with enough neurons can capture the underlying patterns in data without overfitting. The rectified linear unit (ReLU) activation function is used in MLPs because it is simple and effective. The Adam optimizer was used because it is well-suited for training MLPs on big datasets with multiple characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3349354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "mlp_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp_classifier.predict(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e6f48",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be48d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.9523809523809523\n",
      "Recall: 0.9302325581395349\n",
      "F1 Score: 0.9411764705882352\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = recall_score(y_test, y_pred, pos_label='M')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e92cd",
   "metadata": {},
   "source": [
    " The accuracy of 95.61% suggests that the model's overall performance is decent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb185a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
